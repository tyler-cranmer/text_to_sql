{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9a3dd5b80be64b5f980c43e347770826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59e97ccd3d93466db28c48c5bb5b5194",
              "IPY_MODEL_ade32659c42b4bb4b6716edd762fa923",
              "IPY_MODEL_f3a6ad78b1e54e4881c71fce2c518070"
            ],
            "layout": "IPY_MODEL_89de4f46e4754904a2aad8baf511066c"
          }
        },
        "59e97ccd3d93466db28c48c5bb5b5194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_610866e15dae44e4983f42b8a02cb5d9",
            "placeholder": "​",
            "style": "IPY_MODEL_6752617021c94911bc29def961b60270",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ade32659c42b4bb4b6716edd762fa923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99eb924d5235491ea37381040ecbf879",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_288b52dde297432f89058e38a2a28c46",
            "value": 4
          }
        },
        "f3a6ad78b1e54e4881c71fce2c518070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03aed867be3a4a13a957d12d0a8dab07",
            "placeholder": "​",
            "style": "IPY_MODEL_6e1311d0f8a046dabb3a80557e634c5c",
            "value": " 4/4 [00:03&lt;00:00,  1.26it/s]"
          }
        },
        "89de4f46e4754904a2aad8baf511066c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "610866e15dae44e4983f42b8a02cb5d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6752617021c94911bc29def961b60270": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99eb924d5235491ea37381040ecbf879": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "288b52dde297432f89058e38a2a28c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03aed867be3a4a13a957d12d0a8dab07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e1311d0f8a046dabb3a80557e634c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c450311d49ab48b29bf70c49bfc756db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fddf622a84c483381d00891ee351390",
              "IPY_MODEL_535cb37c99904436b24bd5785eb34d3f",
              "IPY_MODEL_d6be058124f9417da31449291ad263b3"
            ],
            "layout": "IPY_MODEL_a3a2b5fbb0cd40eabcea0671e859ad95"
          }
        },
        "5fddf622a84c483381d00891ee351390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d5e7e7eff1c43b5ba8182d0ff1c3388",
            "placeholder": "​",
            "style": "IPY_MODEL_1e8d47c53d2f491788ceee4b1a627029",
            "value": "Map: 100%"
          }
        },
        "535cb37c99904436b24bd5785eb34d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8515cf05d5974406a0a2ccb9f1b32f6c",
            "max": 1167,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_541f1607f3c7485f9a91efbb4bb1ed7a",
            "value": 1167
          }
        },
        "d6be058124f9417da31449291ad263b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d5fb3a01b0e4a96bd801d61edcc2022",
            "placeholder": "​",
            "style": "IPY_MODEL_15cd870d1fa543e2b55ed6440f564da3",
            "value": " 1167/1167 [00:00&lt;00:00, 10270.26 examples/s]"
          }
        },
        "a3a2b5fbb0cd40eabcea0671e859ad95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d5e7e7eff1c43b5ba8182d0ff1c3388": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e8d47c53d2f491788ceee4b1a627029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8515cf05d5974406a0a2ccb9f1b32f6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "541f1607f3c7485f9a91efbb4bb1ed7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d5fb3a01b0e4a96bd801d61edcc2022": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15cd870d1fa543e2b55ed6440f564da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9qM8gYAjgcb"
      },
      "outputs": [],
      "source": [
        "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from peft import LoraConfig, PeftModel, get_peft_model\n",
        "from trl import SFTTrainer\n",
        "import json\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from typing import List\n",
        "import datasets"
      ],
      "metadata": {
        "id": "6TzAB8nfjnF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULT_SYSTEM_PROMPT =\"\"\"Given the following SQL tables, your job is to write a queries given a user’s request. If you think you cannot get the correct SQL, answer with 'null'.\n",
        "\n",
        "CREATE TABLE admissions ( row_id INT NOT NULL PRIMARY KEY, subject_id INT NOT NULL, hadm_id INT NOT NULL UNIQUE,admittime TIMESTAMP(0) NOT NULL, dischtime TIMESTAMP(0), admission_type VARCHAR(50) NOT NULL, admission_location VARCHAR(50) NOT NULL, discharge_location VARCHAR(50), insurance VARCHAR(255) NOT NULL, language VARCHAR(10), marital_status VARCHAR(50), age INT NOT NULL, FOREIGN KEY(subject_id) REFERENCES patients(subject_id));\n",
        "CREATE TABLE chartevents ( row_id INT NOT NULL PRIMARY KEY, subject_id INT NOT NULL, hadm_id INT NOT NULL, stay_id INT NOT NULL,itemid INT NOT NULL, charttime TIMESTAMP(0) NOT NULL, valuenum DOUBLE PRECISION, valueuom VARCHAR(50), FOREIGN KEY(hadm_id) REFERENCES admissions(hadm_id), FOREIGN KEY(stay_id) REFERENCES icustays(stay_id), FOREIGN KEY(itemid) REFERENCES d_items(itemid) );\n",
        "CREATE TABLE cost ( row_id INT NOT NULL PRIMARY KEY, subject_id INT NOT NULL, hadm_id INT NOT NULL, event_type VARCHAR(20) NOT NULL, event_id INT NOT NULL, chargetime TIMESTAMP(0) NOT NULL, cost DOUBLE PRECISION NOT NULL, FOREIGN KEY(hadm_id) REFERENCES admissions(hadm_id), FOREIGN KEY(event_id) REFERENCES diagnoses_icd(row_id), FOREIGN KEY(event_id) REFERENCES procedures_icd(row_id), FOREIGN KEY(event_id) REFERENCES labevents(row_id), FOREIGN KEY(event_id) REFERENCES prescriptions(row_id));\n",
        "CREATE TABLE d_icd_diagnoses ( row_id INT NOT NULL PRIMARY KEY, icd_code VARCHAR(10) NOT NULL UNIQUE, long_title VARCHAR(255) NOT NULL);\n",
        "CREATE TABLE d_icd_procedures ( row_id INT NOT NULL PRIMARY KEY, icd_code VARCHAR(10) NOT NULL UNIQUE, long_title VARCHAR(255) NOT NULL);\n",
        "CREATE TABLE d_items ( row_id INT NOT NULL PRIMARY KEY, itemid INT NOT NULL UNIQUE, label VARCHAR(200) NOT NULL, abbreviation VARCHAR(200) NOT NULL, linksto VARCHAR(50) NOT NULL);\n",
        "CREATE TABLE d_labitems (row_id INT NOT NULL PRIMARY KEY, itemid INT NOT NULL UNIQUE, label VARCHAR(200));\n",
        "CREATE TABLE diagnoses_icd ( row_id INT NOT NULL PRIMARY KEY, subject_id INT NOT NULL, hadm_id INT NOT NULL, icd_code VARCHAR(10) NOT NULL, charttime TIMESTAMP(0) NOT NULL, FOREIGN KEY(hadm_id) REFERENCES admissions(hadm_id), FOREIGN KEY(icd_code) REFERENCES d_icd_diagnoses(icd_code));\n",
        "CREATE TABLE icustays ( row_id INT NOT NULL PRIMARY KEY, subject_id INT NOT NULL, hadm_id INT NOT NULL, stay_id INT NOT NULL UNIQUE, first_careunit VARCHAR(20) NOT NULL, last_careunit VARCHAR(20) NOT NULL, intime TIMESTAMP(0) NOT NULL, outtime TIMESTAMP(0), FOREIGN KEY(hadm_id) REFERENCES admissions(hadm_id) );\n",
        "CREATE TABLE inputevents ( row_id INT NOT NULL PRIMARY KEY, subject_id INT NOT NULL, hadm_id INT NOT NULL, stay_id INT NOT NULL, starttime TIMESTAMP(0) NOT NULL, itemid INT NOT NULL, amount DOUBLE PRECISION, FOREIGN KEY(hadm_id) REFERENCES admissions(hadm_id), FOREIGN KEY(stay_id) REFERENCES icustays(stay_id), FOREIGN KEY(itemid) REFERENCES d_items(itemid));\n",
        "CREATE TABLE labevents ( row_id INT NOT NULL PRIMARY KEY, subject_id INT NOT NULL, hadm_id INT NOT NULL, mitemid INT NOT NULL, charttime TIMESTAMP(0), valuenum DOUBLE PRECISION, valueuom VARCHAR(20), FOREIGN KEY(hadm_id) REFERENCES admissions(hadm_id), FOREIGN KEY(itemid) REFERENCES d_labitems(itemid));\n",
        "CREATE TABLE microbiologyevents ( row_id INT NOT NULL PRIMARY KEY, subject_id INT NOT NULL, hadm_id INT NOT NULL, charttime TIMESTAMP(0) NOT NULL, spec_type_desc VARCHAR(100), test_name VARCHAR(100), org_name VARCHAR(100), FOREIGN KEY(hadm_id) REFERENCES admissions(hadm_id));\n",
        "CREATE TABLE outputevents ( row_id INT NOT NULL PRIMARY KEY, subject_id INT NOT NULL, hadm_id INT NOT NULL, stay_id INT NOT NULL, charttime TIMESTAMP(0) NOT NULL, itemid INT NOT NULL, value DOUBLE PRECISION, FOREIGN KEY(hadm_id) REFERENCES admissions(hadm_id), FOREIGN KEY(stay_id) REFERENCES icustays(stay_id), FOREIGN KEY(itemid) REFERENCES d_items(itemid) );\n",
        "CREATE TABLE patients ( row_id INT NOT NULL PRIMARY KEY, subject_id INT NOT NULL UNIQUE, gender VARCHAR(5) NOT NULL, dob TIMESTAMP(0) NOT NULL, dod TIMESTAMP(0));\n",
        "CREATE TABLE prescriptions ( row_id INT NOT NULL PRIMARY KEY, subject_id INT NOT NULL, hadm_id INT NOT NULL, starttime TIMESTAMP(0) NOT NULL, stoptime TIMESTAMP(0), drug VARCHAR(255) NOT NULL, dose_val_rx VARCHAR(100) NOT NULL, dose_unit_rx VARCHAR(50) NOT NULL, route VARCHAR(50) NOT NULL, FOREIGN KEY(hadm_id) REFERENCES admissions(hadm_id));\n",
        "CREATE TABLE procedures_icd ( row_id INT NOT NULL PRIMARY KEY, subject_id INT NOT NULL, hadm_id INT NOT NULL, icd_code VARCHAR(10) NOT NULL, charttime TIMESTAMP(0) NOT NULL, FOREIGN KEY(hadm_id) REFERENCES admissions(hadm_id), FOREIGN KEY(icd_code) REFERENCES d_icd_procedures(icd_code));\n",
        "CREATE TABLE transfers ( row_id INT NOT NULL PRIMARY KEY, subject_id INT NOT NULL, hadm_id INT NOT NULL, transfer_id INT NOT NULL, eventtype VARCHAR(20) NOT NULL, careunit VARCHAR(20), intime TIMESTAMP(0) NOT NULL, outtime TIMESTAMP(0), FOREIGN KEY(hadm_id) REFERENCES admissions(hadm_id));\n",
        "\"\"\".strip()\n",
        "\n",
        "# List of all tables\n",
        "tables = [\n",
        "    \"admissions\", \"chartevents\", \"cost\", \"d_icd_diagnoses\", \"d_icd_procedures\",\n",
        "    \"d_items\", \"d_labitems\", \"diagnoses_icd\", \"icustays\", \"inputevents\",\n",
        "    \"labevents\", \"microbiologyevents\", \"outputevents\", \"patients\",\n",
        "    \"prescriptions\", \"procedures_icd\", \"transfers\"\n",
        "]\n",
        "\n",
        "def extract_table_definition(table_name, prompt):\n",
        "    start = prompt.find(f\"CREATE TABLE {table_name}\")\n",
        "    if start == -1:\n",
        "        return None\n",
        "    end = prompt.find(\"CREATE TABLE\", start + 1)\n",
        "    if end == -1:\n",
        "        end = len(prompt)\n",
        "    return prompt[start:end].strip()\n",
        "\n",
        "def extract_relevant_foreign_keys(table_list, foreign_keys):\n",
        "    relevant_keys = []\n",
        "    for key in foreign_keys:\n",
        "        # Split the foreign key on '=' and then further split on '.' to isolate table names\n",
        "        tables_in_key = set([part.strip().split('.')[0] for part in key.replace(\" \", \"\").split('=')])\n",
        "        # Check if all tables in the foreign key are in the provided table list\n",
        "        if all(table in table_list for table in tables_in_key):\n",
        "            relevant_keys.append(key)\n",
        "    return relevant_keys\n",
        "\n",
        "def construct_custom_system_prompt(sql_query, original_prompt, table_list):\n",
        "    included_tables = []\n",
        "    foreign_keys_tables = []\n",
        "    for table in table_list:\n",
        "        if table in sql_query:\n",
        "            table_def = extract_table_definition(table, original_prompt)\n",
        "            foreign_keys_tables.append(table)\n",
        "            if table_def:\n",
        "                included_tables.append(table_def)\n",
        "\n",
        "    new_prompt = \"Given the following SQL tables, your job is to write a sql query for a given user’s request. If you think you cannot get the correct SQL, answer with 'null'.\\n\\n\"\n",
        "    new_prompt += \"\\n\".join(included_tables)\n",
        "    new_prompt += \"\\n\\n #diction \\n SQL \\n\"\n",
        "    return new_prompt.strip()\n",
        "\n",
        "\n",
        "def merge_datasets(questions: List[dict], sql_queries: List[dict], tables: List[str], system_prompt: str = DEFAULT_SYSTEM_PROMPT):\n",
        "    merged_dataset = []\n",
        "    for question_item in questions:\n",
        "        item_id = question_item['id']\n",
        "        if item_id in sql_queries:\n",
        "            merged_item = {\n",
        "                'id': item_id,\n",
        "                \"system_prompt\": construct_custom_system_prompt(sql_queries[item_id], system_prompt, tables),\n",
        "                'question': question_item['question'],\n",
        "                'sql_query': sql_queries[item_id]\n",
        "            }\n",
        "            merged_dataset.append(merged_item)\n",
        "    return merged_dataset"
      ],
      "metadata": {
        "id": "F4GPHQLtjqAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS57vFhjvXg9",
        "outputId": "b3e8816b-c4e0-4484-cb0a-e14b00f08e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions = json.load(open('/content/drive/MyDrive/Colab_Notebooks/CSCI 5922/final project/data_text2sql/mimic_iv/test/data.json'))['data'] #test data\n",
        "sql_queries = json.load(open('/content/drive/MyDrive/Colab_Notebooks/CSCI 5922/final project/data_text2sql/mimic_iv/test/label.json')) # test data"
      ],
      "metadata": {
        "id": "BdYywIAqjvIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = merge_datasets(questions, sql_queries, tables)\n",
        "test_data = datasets.Dataset.from_list(test_dataset)"
      ],
      "metadata": {
        "id": "5_qnk-F4jzs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\""
      ],
      "metadata": {
        "id": "P27mrJbU3boQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      use_safetensors=True,\n",
        "      trust_remote_code=True,\n",
        "  ).to('cuda:0')"
      ],
      "metadata": {
        "id": "VAiYP_Mgj6Ke",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "9a3dd5b80be64b5f980c43e347770826",
            "59e97ccd3d93466db28c48c5bb5b5194",
            "ade32659c42b4bb4b6716edd762fa923",
            "f3a6ad78b1e54e4881c71fce2c518070",
            "89de4f46e4754904a2aad8baf511066c",
            "610866e15dae44e4983f42b8a02cb5d9",
            "6752617021c94911bc29def961b60270",
            "99eb924d5235491ea37381040ecbf879",
            "288b52dde297432f89058e38a2a28c46",
            "03aed867be3a4a13a957d12d0a8dab07",
            "6e1311d0f8a046dabb3a80557e634c5c"
          ]
        },
        "outputId": "1d059991-4cb6-4fdf-93bd-31fe17c1ffa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a3dd5b80be64b5f980c43e347770826"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B-Instruct and are newly initialized: ['model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.24.self_attn.rotary_emb.inv_freq', 'model.layers.25.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.22.self_attn.rotary_emb.inv_freq', 'model.layers.23.self_attn.rotary_emb.inv_freq', 'model.layers.29.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.26.self_attn.rotary_emb.inv_freq', 'model.layers.28.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.27.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.30.self_attn.rotary_emb.inv_freq', 'model.layers.31.self_attn.rotary_emb.inv_freq']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DIR = \"/content/drive/MyDrive/Colab_Notebooks/CSCI 5922/final project/llama3_all_data_2\""
      ],
      "metadata": {
        "id": "4A2oNcG9j9Ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load LLaMA tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training"
      ],
      "metadata": {
        "id": "WVoWImaQj83M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nEOS token: \", tokenizer.eos_token)\n",
        "print(\"EOS token id:\", tokenizer.eos_token_id)\n",
        "print(\"\\nPad token: \", tokenizer.pad_token)\n",
        "print(\"Pad token id: \", tokenizer.pad_token_id)"
      ],
      "metadata": {
        "id": "QvaL5nXMkHXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55f04a92-4078-4afa-9cb8-7ac861b842a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using pad_token, but it is not set yet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EOS token:  <|end_of_text|>\n",
            "EOS token id: 128001\n",
            "\n",
            "Pad token:  None\n",
            "Pad token id:  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if '|<pad>|' not in tokenizer.get_vocab():\n",
        "\n",
        "  #Add pad token\n",
        "  tokenizer.add_tokens(['|<pad>|'])\n",
        "\n",
        "#set the pad token\n",
        "tokenizer.pad_token = '|<pad>|'\n",
        "\n",
        "#resize token embeddings\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "#update pad token id in model and its config\n",
        "model.pad_token_id = tokenizer.pad_token_id\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "\n",
        "#check that equality\n",
        "assert model.pad_token_id == tokenizer.pad_token_id, \"The model's pad token ID does not match the tokenizer's pad token\"\n",
        "\n",
        "print(\"tokenizer pad token ID: \", tokenizer.pad_token_id)\n",
        "print(\"Model pad token ID: \", model.pad_token_id)\n",
        "print(\"Model config pad token ID: \", model.config.pad_token_id)\n",
        "\n",
        "print(model.config)"
      ],
      "metadata": {
        "id": "ESW2gsQwkHTE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f9331a8-d4d0-452e-c796-a0fdea4039ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer pad token ID:  128256\n",
            "Model pad token ID:  128256\n",
            "Model config pad token ID:  128256\n",
            "LlamaConfig {\n",
            "  \"_name_or_path\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pad_token_id\": 128256,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.31.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128257\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_string = ['<|start_header_id|>']\n",
        "\n",
        "encoded_sample = tokenizer(sample_string, truncation=True, padding= True, max_length=1024, return_attention_mask=True)\n",
        "\n",
        "token_count = len(encoded_sample)\n",
        "\n",
        "BOS_token_id = tokenizer.bos_token_id\n",
        "EOS_token_id = tokenizer.eos_token_id\n",
        "\n",
        "BOS_token = tokenizer.decode([BOS_token_id])\n",
        "EOS_token = tokenizer.decode([EOS_token_id])\n",
        "\n",
        "\n",
        "print(f\"Beginning of the sequence: {sample_string[0]} (BOS token: {BOS_token}), id: {BOS_token_id}\")\n",
        "print(f\"End of the sequence: {sample_string[-1]} (EOS token: {EOS_token}, id: {EOS_token_id})\")\n",
        "\n",
        "print(f\"The number of tokens in the string is: {token_count}\")\n",
        "print(f\"the ids are: {encoded_sample}\")\n",
        "\n",
        "\n",
        "decoded_sample = tokenizer.decode(encoded_sample['input_ids'][0], skip_special_tokens=False)\n",
        "\n",
        "print(f\"the decoded string is {decoded_sample}\")"
      ],
      "metadata": {
        "id": "1st5QgrdkHJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d831250-5b2d-4512-b315-ccbe75608691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning of the sequence: <|start_header_id|> (BOS token: <|begin_of_text|>), id: 128000\n",
            "End of the sequence: <|start_header_id|> (EOS token: <|end_of_text|>, id: 128001)\n",
            "The number of tokens in the string is: 2\n",
            "the ids are: {'input_ids': [[128000, 128006]], 'attention_mask': [[1, 1]]}\n",
            "the decoded string is <|begin_of_text|><|start_header_id|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset_Right_Padding(Dataset):\n",
        "  def __init__(self, encodings, response_lengths):\n",
        "    self.encodings = encodings\n",
        "    self.response_lengths = response_lengths\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
        "\n",
        "    # Set labels to the same as input_ids\n",
        "    item['labels'] = item['input_ids'].clone()\n",
        "    # Find the index of the first padding token\n",
        "    padding_idx = 128256\n",
        "    first_pad_index = (item['input_ids'] == padding_idx).nonzero(as_tuple=True)[0][0]\n",
        "\n",
        "    # Calculate the actual end of the sequence before padding\n",
        "    actual_end = first_pad_index\n",
        "\n",
        "    # Shift labels to the left by one position up to the actual end of the sequence\n",
        "    item['labels'][:actual_end-1] = item['input_ids'][1:actual_end]\n",
        "    item['labels'][actual_end-1] = 2  # Place EOS token at the end of the actual sequence\n",
        "\n",
        "\n",
        "    # Create a loss mask that is 1 for the actual response, excluding padding\n",
        "    item['loss_mask'] = torch.zeros_like(item[\"input_ids\"])\n",
        "    response_start_position = first_pad_index - self.response_lengths[idx]\n",
        "    item['loss_mask'][response_start_position-2:first_pad_index] = 1\n",
        "\n",
        "    return item\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.encodings['input_ids'])"
      ],
      "metadata": {
        "id": "tf7FE4In4GyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(dataset, tokenizer, max_length=1024):\n",
        "    # Define the roles and markers\n",
        "    S_HEAD, E_HEAD = \"<|start_header_id|>\", \"<|end_header_id|>\"\n",
        "    E_TURN = '<|eot_id|>'\n",
        "    B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
        "\n",
        "    # Apply transformation to each item in the dataset\n",
        "    formatted_dataset = dataset.map(\n",
        "        lambda x: {\n",
        "            \"input_text\": \"\".join([\n",
        "                f\"{S_HEAD}system{E_HEAD} {x['system_prompt'].strip()}{E_TURN}\",\n",
        "                f\"{S_HEAD}user{E_HEAD} {x['question'].strip()}{E_TURN}\",\n",
        "                f\"{S_HEAD}assistant{E_HEAD} {x['sql_query'].strip()} {E_TURN}\"  # appending the EOS token in text data...\n",
        "            ]),\n",
        "            \"response_text\": \"\".join([\n",
        "                f\"{x['sql_query'].strip()}\"  # appending the EOS token in text data...\n",
        "            ])\n",
        "        }\n",
        "    )\n",
        "    #tokenize the dataset\n",
        "    encodings = tokenizer([dialogue['input_text'] for dialogue in formatted_dataset], truncation=True, return_tensors='pt', max_length=max_length, padding=True)\n",
        "\n",
        "    response_length = [len(tokenizer.encode(dialogue['response_text'], truncation = True, max_length=max_length)) for dialogue in formatted_dataset]\n",
        "\n",
        "    text_dataset = TextDataset_Right_Padding(encodings, response_length)\n",
        "    return text_dataset"
      ],
      "metadata": {
        "id": "gHoOPNA4kQzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_ = prepare_dataset(test_data, tokenizer)"
      ],
      "metadata": {
        "id": "N8Ixj0FHkTwq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c450311d49ab48b29bf70c49bfc756db",
            "5fddf622a84c483381d00891ee351390",
            "535cb37c99904436b24bd5785eb34d3f",
            "d6be058124f9417da31449291ad263b3",
            "a3a2b5fbb0cd40eabcea0671e859ad95",
            "1d5e7e7eff1c43b5ba8182d0ff1c3388",
            "1e8d47c53d2f491788ceee4b1a627029",
            "8515cf05d5974406a0a2ccb9f1b32f6c",
            "541f1607f3c7485f9a91efbb4bb1ed7a",
            "6d5fb3a01b0e4a96bd801d61edcc2022",
            "15cd870d1fa543e2b55ed6440f564da3"
          ]
        },
        "outputId": "6e183824-92fa-45e5-d75d-9ef238d1492a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1167 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c450311d49ab48b29bf70c49bfc756db"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_item = test_data_[18]\n",
        "\n",
        "print(f\"Dimensions of input_ids: {sample_item['input_ids'].shape}\")\n",
        "print(f\"Dimensions of attention_mask: {sample_item['attention_mask'].shape}\")\n",
        "print(f\"Dimensions of loss_mask: {sample_item['loss_mask'].shape}\")\n",
        "print(f\"Dimensions of labels: {sample_item['labels'].shape}\")\n",
        "\n",
        "num_tokens_to_print = 200\n",
        "\n",
        "print(\"\\nTokens at the start of the sample:\")\n",
        "print(sample_item['input_ids'][:num_tokens_to_print].tolist())\n",
        "print(tokenizer.convert_ids_to_tokens(sample_item['input_ids'][:num_tokens_to_print].tolist()))\n",
        "\n",
        "print(\"\\nLabels at the start of the sample:\")\n",
        "print(sample_item['labels'][:num_tokens_to_print].tolist())\n",
        "print(tokenizer.convert_ids_to_tokens(sample_item['labels'][:num_tokens_to_print].tolist()))\n",
        "\n",
        "print(\"\\nAttention Mask at the start of the sample:\")\n",
        "print(sample_item['attention_mask'][:num_tokens_to_print].tolist())\n",
        "\n",
        "print(\"\\nLoss Mask at the start of the sample:\")\n",
        "print(sample_item['loss_mask'][:num_tokens_to_print].tolist())\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nTokens at the end of the sample:\")\n",
        "print(sample_item['input_ids'][-num_tokens_to_print:].tolist())\n",
        "print(tokenizer.convert_ids_to_tokens(sample_item['input_ids'][-num_tokens_to_print:].tolist()))\n",
        "\n",
        "print(\"\\nLabels at the end of the sample:\")\n",
        "print(sample_item['labels'][-num_tokens_to_print:].tolist())\n",
        "print(tokenizer.convert_ids_to_tokens(sample_item['labels'][-num_tokens_to_print:].tolist()))\n",
        "\n",
        "print(\"\\nAttention Mask at the end of the sample:\")\n",
        "print(sample_item['attention_mask'][-num_tokens_to_print:].tolist())\n",
        "\n",
        "print(\"\\nLoss Mask at the end of the sample:\")\n",
        "print(sample_item['loss_mask'][-num_tokens_to_print:].tolist())"
      ],
      "metadata": {
        "id": "g2z7y-ZLkbD4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de83b547-7098-4478-8b45-19a0e0c88b86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions of input_ids: torch.Size([768])\n",
            "Dimensions of attention_mask: torch.Size([768])\n",
            "Dimensions of loss_mask: torch.Size([768])\n",
            "Dimensions of labels: torch.Size([768])\n",
            "\n",
            "Tokens at the start of the sample:\n",
            "[128000, 128006, 9125, 128007, 16644, 279, 2768, 8029, 12920, 11, 701, 2683, 374, 311, 3350, 264, 5822, 3319, 369, 264, 2728, 1217, 753, 1715, 13, 1442, 499, 1781, 499, 4250, 636, 279, 4495, 8029, 11, 4320, 449, 364, 2994, 6, 2055, 674, 67, 2538, 720, 8029, 128009, 128006, 882, 128007, 1796, 682, 279, 58784, 315, 279, 6978, 889, 1051, 14992, 1109, 220, 1691, 13, 128009, 128006, 78191, 128007, 854, 220, 128009, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256]\n",
            "['<|begin_of_text|>', '<|start_header_id|>', 'system', '<|end_header_id|>', 'ĠGiven', 'Ġthe', 'Ġfollowing', 'ĠSQL', 'Ġtables', ',', 'Ġyour', 'Ġjob', 'Ġis', 'Ġto', 'Ġwrite', 'Ġa', 'Ġsql', 'Ġquery', 'Ġfor', 'Ġa', 'Ġgiven', 'Ġuser', 'âĢĻs', 'Ġrequest', '.', 'ĠIf', 'Ġyou', 'Ġthink', 'Ġyou', 'Ġcannot', 'Ġget', 'Ġthe', 'Ġcorrect', 'ĠSQL', ',', 'Ġanswer', 'Ġwith', \"Ġ'\", 'null', \"'\", '.ĊĊĊĊ', 'Ġ#', 'd', 'iction', 'ĠĊ', 'ĠSQL', '<|eot_id|>', '<|start_header_id|>', 'user', '<|end_header_id|>', 'ĠList', 'Ġall', 'Ġthe', 'Ġadvisors', 'Ġof', 'Ġthe', 'Ġpatients', 'Ġwho', 'Ġwere', 'Ġyounger', 'Ġthan', 'Ġ', '21', '.', '<|eot_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', 'Ġnull', 'Ġ', '<|eot_id|>', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|']\n",
            "\n",
            "Labels at the start of the sample:\n",
            "[128006, 9125, 128007, 16644, 279, 2768, 8029, 12920, 11, 701, 2683, 374, 311, 3350, 264, 5822, 3319, 369, 264, 2728, 1217, 753, 1715, 13, 1442, 499, 1781, 499, 4250, 636, 279, 4495, 8029, 11, 4320, 449, 364, 2994, 6, 2055, 674, 67, 2538, 720, 8029, 128009, 128006, 882, 128007, 1796, 682, 279, 58784, 315, 279, 6978, 889, 1051, 14992, 1109, 220, 1691, 13, 128009, 128006, 78191, 128007, 854, 220, 128009, 2, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256]\n",
            "['<|start_header_id|>', 'system', '<|end_header_id|>', 'ĠGiven', 'Ġthe', 'Ġfollowing', 'ĠSQL', 'Ġtables', ',', 'Ġyour', 'Ġjob', 'Ġis', 'Ġto', 'Ġwrite', 'Ġa', 'Ġsql', 'Ġquery', 'Ġfor', 'Ġa', 'Ġgiven', 'Ġuser', 'âĢĻs', 'Ġrequest', '.', 'ĠIf', 'Ġyou', 'Ġthink', 'Ġyou', 'Ġcannot', 'Ġget', 'Ġthe', 'Ġcorrect', 'ĠSQL', ',', 'Ġanswer', 'Ġwith', \"Ġ'\", 'null', \"'\", '.ĊĊĊĊ', 'Ġ#', 'd', 'iction', 'ĠĊ', 'ĠSQL', '<|eot_id|>', '<|start_header_id|>', 'user', '<|end_header_id|>', 'ĠList', 'Ġall', 'Ġthe', 'Ġadvisors', 'Ġof', 'Ġthe', 'Ġpatients', 'Ġwho', 'Ġwere', 'Ġyounger', 'Ġthan', 'Ġ', '21', '.', '<|eot_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', 'Ġnull', 'Ġ', '<|eot_id|>', '#', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|']\n",
            "\n",
            "Attention Mask at the start of the sample:\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "Loss Mask at the start of the sample:\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "Tokens at the end of the sample:\n",
            "[128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256]\n",
            "['|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|']\n",
            "\n",
            "Labels at the end of the sample:\n",
            "[128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256]\n",
            "['|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|']\n",
            "\n",
            "Attention Mask at the end of the sample:\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "Loss Mask at the end of the sample:\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_mask_list = sample_item['loss_mask'].tolist()\n",
        "first_non_zero_loss_id = loss_mask_list.index(1)\n",
        "last_non_zero_loss_id = first_non_zero_loss_id\n",
        "for i in range(first_non_zero_loss_id, len(loss_mask_list)):\n",
        "  if loss_mask_list[i] == 1:\n",
        "    last_non_zero_loss_id = i\n",
        "  else:\n",
        "    break"
      ],
      "metadata": {
        "id": "ulFzk8JLkeJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(first_non_zero_loss_id)\n",
        "print(sample_item['input_ids'].tolist()[first_non_zero_loss_id-5:first_non_zero_loss_id])\n",
        "print(tokenizer.convert_ids_to_tokens(sample_item['input_ids'].tolist()[first_non_zero_loss_id-5:first_non_zero_loss_id+5]))\n",
        "print(sample_item['labels'].tolist()[first_non_zero_loss_id])\n",
        "print(tokenizer.convert_ids_to_tokens(sample_item['labels'].tolist()[first_non_zero_loss_id]))"
      ],
      "metadata": {
        "id": "VeD-U6amkgSW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a0f20d1-3747-41a1-82ab-107fb61ff204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67\n",
            "[1691, 13, 128009, 128006, 78191]\n",
            "['21', '.', '<|eot_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', 'Ġnull', 'Ġ', '<|eot_id|>', '|<pad>|']\n",
            "854\n",
            "Ġnull\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(last_non_zero_loss_id)\n",
        "print(sample_item['input_ids'].tolist()[last_non_zero_loss_id])\n",
        "print(tokenizer.convert_ids_to_tokens(sample_item['input_ids'].tolist()[last_non_zero_loss_id]))\n",
        "print(sample_item['labels'].tolist()[last_non_zero_loss_id])\n",
        "print(tokenizer.convert_ids_to_tokens(sample_item['labels'].tolist()[last_non_zero_loss_id]))\n",
        "\n",
        "print(tokenizer.convert_ids_to_tokens(sample_item['input_ids'].tolist()[last_non_zero_loss_id - 5: last_non_zero_loss_id+5]))\n",
        "print(sample_item['labels'].tolist()[last_non_zero_loss_id])\n",
        "print(tokenizer.convert_ids_to_tokens(sample_item['labels'].tolist()[last_non_zero_loss_id-5 : last_non_zero_loss_id+5]))"
      ],
      "metadata": {
        "id": "DfZXCVIRki07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4296e9a7-9849-49c2-b355-f2234a3c44c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70\n",
            "128009\n",
            "<|eot_id|>\n",
            "2\n",
            "#\n",
            "['<|start_header_id|>', 'assistant', '<|end_header_id|>', 'Ġnull', 'Ġ', '<|eot_id|>', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|']\n",
            "2\n",
            "['assistant', '<|end_header_id|>', 'Ġnull', 'Ġ', '<|eot_id|>', '#', '|<pad>|', '|<pad>|', '|<pad>|', '|<pad>|']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_model = PeftModel.from_pretrained(model, OUTPUT_DIR, torch_dtype=torch.float16)\n",
        "print(f\"Running merge_and_unload\")\n",
        "combined_model = combined_model.merge_and_unload()"
      ],
      "metadata": {
        "id": "kYkIXecbj8qF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b12e1ac9-87f4-4bde-c581-78d414a63d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running merge_and_unload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_after_token(text, token='assistant'):\n",
        "    # Search for the token in the text\n",
        "    match = re.search(re.escape(token), text)\n",
        "\n",
        "    # If the token is found, return everything after it\n",
        "    if match:\n",
        "        return text[match.end():].strip()\n",
        "    else:\n",
        "        return \"Token not found.\""
      ],
      "metadata": {
        "id": "K0Ngd9VAnIzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference(system_prompt, query):\n",
        "    runtimeFlag = \"cuda:0\"\n",
        "\n",
        "    S_HEAD, E_HEAD = \"<|start_header_id|>\", \"<|end_header_id|>\"\n",
        "    E_TURN = '<|eot_id|>'\n",
        "\n",
        "    prompt = f\"{S_HEAD}system{E_HEAD} {system_prompt.strip()}{E_TURN}\\n{S_HEAD}user{E_HEAD} {query.strip()}{E_TURN}{S_HEAD}assistant{E_HEAD}\"\n",
        "\n",
        "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(runtimeFlag)\n",
        "\n",
        "    outputs = combined_model.generate(**inputs, max_new_tokens=500, pad_token_id=tokenizer.pad_token_id)\n",
        "\n",
        "    # Decode and print the generated text\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return extract_after_token(generated_text)"
      ],
      "metadata": {
        "id": "McpUVaSJksPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def append_to_json(new_data, file_path):\n",
        "    # Check if file exists and is not empty\n",
        "    if not os.path.isfile(file_path) or os.stat(file_path).st_size == 0:\n",
        "        with open(file_path, 'w') as file:\n",
        "            json.dump(new_data, file, indent=4)  # Initialize file with first data element in a list\n",
        "    else:\n",
        "        with open(file_path, 'r+') as file:\n",
        "            data = json.load(file)  # Load the existing data into a dictionary\n",
        "            data.update(new_data)  # Update the dictionary with the new data\n",
        "            file.seek(0)  # Rewind to the start of the file\n",
        "            json.dump(data, file, indent=4)  # Dump the updated dictionary back into the file\n",
        "            file.truncate()  # Truncate the file in case the new data is smaller than the old"
      ],
      "metadata": {
        "id": "NihDZVDjooSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = os.path.join(OUTPUT_DIR, 'answers.json')\n",
        "\n",
        "for num in tqdm(range(len(test_dataset)), desc=\"Processing dataset\"):\n",
        "    entry = test_dataset[num]\n",
        "    system = entry['system_prompt']\n",
        "    query = entry['question']\n",
        "    ground_truth = entry['sql_query']\n",
        "    output = run_inference(system, query)\n",
        "\n",
        "    record = {\n",
        "      entry['id'] : output\n",
        "    }\n",
        "\n",
        "    # Append record to JSON file\n",
        "    append_to_json(record, filename)\n",
        "\n"
      ],
      "metadata": {
        "id": "TI___mXwks5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1484b709-26f3-459a-ccba-005bc66b40b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing dataset: 100%|██████████| 1167/1167 [1:09:58<00:00,  3.60s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BWccbXQy_XXF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}